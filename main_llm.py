#!/usr/bin/env python3
"""
CCGL Analytics System - LLM Integration Main Program
AI-enhanced analysis mode with natural language querying
"""

import argparse
import asyncio
import sys
import os
import yaml
import json
import pandas as pd
from pathlib import Path
from typing import Dict, Any, List, Optional, Union
import time

# Add the project root to the Python path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from ccgl_analytics.utils.logger import get_logger, setup_logging

class LLMProvider:
    """Base class for LLM providers."""
    
    def __init__(self, config: Dict[str, Any]):
        """Initialize LLM provider.
        
        Args:
            config: Provider configuration
        """
        self.config = config
        self.logger = get_logger(__name__)
    
    async def generate_response(self, prompt: str, context: Optional[Dict[str, Any]] = None) -> str:
        """Generate response from LLM.
        
        Args:
            prompt: Input prompt
            context: Optional context information
            
        Returns:
            Generated response
        """
        raise NotImplementedError("Subclasses must implement generate_response")
    
    def is_available(self) -> bool:
        """Check if provider is available and configured.
        
        Returns:
            True if available
        """
        api_key = self.config.get('api_key')
        return bool(api_key and api_key.strip())

class OpenAIProvider(LLMProvider):
    """OpenAI GPT provider."""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.model = config.get('model', 'gpt-4')
        self.max_tokens = config.get('max_tokens', 4000)
        self.temperature = config.get('temperature', 0.7)
    
    async def generate_response(self, prompt: str, context: Optional[Dict[str, Any]] = None) -> str:
        """Generate response using OpenAI API."""
        if not self.is_available():
            return "OpenAI API key not configured."
        
        # Simulate OpenAI API call (in real implementation, use openai library)
        self.logger.info(f"Generating response using OpenAI {self.model}")
        await asyncio.sleep(1)  # Simulate API delay
        
        # Create contextual response
        response = f"""Based on your query about the data analysis:

{prompt}

Here's my analysis:

1. **Data Overview**: I understand you're working with a dataset that requires comprehensive analysis.

2. **Key Insights**: 
   - The data appears to have interesting patterns that warrant further investigation
   - There may be correlations between different variables that could provide business value
   - Anomalies in the data might indicate opportunities or issues that need attention

3. **Recommendations**:
   - Consider segmenting the data by key demographics or time periods
   - Apply clustering algorithms to identify natural groupings
   - Use anomaly detection to find outliers that might represent opportunities

4. **Next Steps**:
   - Perform detailed statistical analysis
   - Create visualizations to better understand patterns
   - Develop predictive models if appropriate

Would you like me to dive deeper into any specific aspect of this analysis?

*Generated by OpenAI {self.model}*"""
        
        return response

class ClaudeProvider(LLMProvider):
    """Anthropic Claude provider."""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.model = config.get('model', 'claude-3-sonnet-20240229')
        self.max_tokens = config.get('max_tokens', 4000)
    
    async def generate_response(self, prompt: str, context: Optional[Dict[str, Any]] = None) -> str:
        """Generate response using Claude API."""
        if not self.is_available():
            return "Anthropic Claude API key not configured."
        
        self.logger.info(f"Generating response using Claude {self.model}")
        await asyncio.sleep(1)  # Simulate API delay
        
        response = f"""I'll help you analyze this data thoughtfully and comprehensively.

Regarding your query: {prompt}

**Analytical Approach:**

Let me break down what I see and recommend:

🔍 **Data Examination**
- First, I'd examine the data structure and quality
- Look for missing values, outliers, and data types
- Understand the business context and objectives

📊 **Statistical Analysis**
- Descriptive statistics to understand distributions
- Correlation analysis to identify relationships
- Hypothesis testing where appropriate

🤖 **Machine Learning Insights**
- Clustering to find natural segments
- Classification or regression based on objectives
- Feature importance and selection

💡 **Business Intelligence**
- Translate technical findings into actionable insights
- Identify opportunities for optimization
- Recommend specific next steps

**Questions for you:**
1. What specific business questions are you trying to answer?
2. What time period does this data cover?
3. Are there any known data quality issues?

I'm ready to dive deeper into any aspect you'd like to explore further.

*Analyzed by Claude {self.model}*"""
        
        return response

class ZhipuAIProvider(LLMProvider):
    """ZhipuAI GLM provider."""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.model = config.get('model', 'glm-4')
    
    async def generate_response(self, prompt: str, context: Optional[Dict[str, Any]] = None) -> str:
        """Generate response using ZhipuAI API."""
        if not self.is_available():
            return "ZhipuAI API key not configured."
        
        self.logger.info(f"Generating response using ZhipuAI {self.model}")
        await asyncio.sleep(1)  # Simulate API delay
        
        response = f"""您好！我来为您分析这个数据问题。

关于您的查询：{prompt}

**智能分析方案：**

🎯 **数据理解**
- 数据维度和规模分析
- 数据质量评估（缺失值、异常值、重复值）
- 业务背景和分析目标确认

📈 **深度分析**
- 描述性统计分析，了解数据分布特征
- 相关性分析，发现变量间关系
- 趋势分析，识别时间序列模式

🔬 **机器学习洞察**
- 聚类分析，发现用户/产品分群
- 异常检测，识别潜在风险或机会
- 预测建模，支持业务决策

💼 **商业价值**
- 将技术发现转化为业务洞察
- 提供可执行的行动建议
- 量化分析的商业影响

**后续建议：**
1. 确定核心业务问题和KPI指标
2. 建立数据质量监控机制
3. 制定基于数据的决策流程

我可以针对您的具体需求提供更详细的分析。

*由智谱AI {self.model}生成*"""
        
        return response

class QwenProvider(LLMProvider):
    """Alibaba Tongyi Qianwen provider."""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.model = config.get('model', 'qwen-turbo')
    
    async def generate_response(self, prompt: str, context: Optional[Dict[str, Any]] = None) -> str:
        """Generate response using Qwen API."""
        if not self.is_available():
            return "Dashscope (Qwen) API key not configured."
        
        self.logger.info(f"Generating response using Qwen {self.model}")
        await asyncio.sleep(1)  # Simulate API delay
        
        response = f"""基于您的数据分析需求，我来提供专业的分析建议。

您的查询：{prompt}

**数据分析策略：**

🔍 **数据探索阶段**
- 数据概览：行数、列数、数据类型分布
- 数据质量评估：完整性、准确性、一致性
- 业务理解：明确分析目标和预期成果

📊 **分析建模阶段**
- 特征工程：数据清洗、变换、衍生
- 统计分析：描述性统计、相关分析、分布检验
- 机器学习：聚类、分类、回归、异常检测

🎯 **洞察提取阶段**
- 模式识别：发现数据中的规律和趋势
- 异常分析：识别值得关注的异常情况
- 关联分析：挖掘变量间的深层关系

💡 **价值转化阶段**
- 业务洞察：将技术结果转化为业务语言
- 行动建议：提供具体可执行的改进方案
- 风险评估：识别潜在风险和机会点

**实施路径：**
1. 制定详细的分析计划和时间表
2. 建立数据质量标准和监控体系
3. 设计可持续的分析和报告机制

请告诉我您希望重点关注哪个方面？

*通义千问{self.model}提供*"""
        
        return response

class LLMManager:
    """Manager for LLM providers."""
    
    def __init__(self, config: Dict[str, Any]):
        """Initialize LLM manager.
        
        Args:
            config: LLM configuration
        """
        self.config = config
        self.logger = get_logger(__name__)
        self.providers = {}
        self._initialize_providers()
    
    def _initialize_providers(self):
        """Initialize all configured providers."""
        providers_config = self.config.get('providers', {})
        
        if 'openai' in providers_config:
            self.providers['openai'] = OpenAIProvider(providers_config['openai'])
        
        if 'claude' in providers_config:
            self.providers['claude'] = ClaudeProvider(providers_config['claude'])
        
        if 'zhipuai' in providers_config:
            self.providers['zhipuai'] = ZhipuAIProvider(providers_config['zhipuai'])
        
        if 'qwen' in providers_config:
            self.providers['qwen'] = QwenProvider(providers_config['qwen'])
        
        available_providers = [name for name, provider in self.providers.items() if provider.is_available()]
        self.logger.info(f"Initialized LLM providers: {available_providers}")
    
    def get_provider(self, provider_name: Optional[str] = None) -> LLMProvider:
        """Get LLM provider by name or default.
        
        Args:
            provider_name: Name of the provider, or None for default
            
        Returns:
            LLM provider instance
        """
        if provider_name is None:
            provider_name = self.config.get('default_provider', 'openai')
        
        if provider_name not in self.providers:
            raise ValueError(f"Provider '{provider_name}' not configured")
        
        provider = self.providers[provider_name]
        if not provider.is_available():
            raise ValueError(f"Provider '{provider_name}' not available (missing API key)")
        
        return provider
    
    def list_available_providers(self) -> List[str]:
        """List all available providers.
        
        Returns:
            List of available provider names
        """
        return [name for name, provider in self.providers.items() if provider.is_available()]

class NaturalLanguageQueryEngine:
    """Engine for processing natural language queries."""
    
    def __init__(self, llm_manager: LLMManager):
        """Initialize query engine.
        
        Args:
            llm_manager: LLM manager instance
        """
        self.llm_manager = llm_manager
        self.logger = get_logger(__name__)
        self.conversation_history = []
    
    async def process_query(self, query: str, data_context: Optional[Dict[str, Any]] = None, provider: Optional[str] = None) -> Dict[str, Any]:
        """Process natural language query.
        
        Args:
            query: Natural language query
            data_context: Optional data context
            provider: Optional specific provider to use
            
        Returns:
            Query processing results
        """
        self.logger.info(f"Processing natural language query: {query[:100]}...")
        
        # Get LLM provider
        llm_provider = self.llm_manager.get_provider(provider)
        
        # Build enhanced prompt with context
        enhanced_prompt = self._build_enhanced_prompt(query, data_context)
        
        # Generate response
        response = await llm_provider.generate_response(enhanced_prompt, data_context)
        
        # Store in conversation history
        self.conversation_history.append({
            'timestamp': pd.Timestamp.now().isoformat(),
            'query': query,
            'provider': provider or self.llm_manager.config.get('default_provider'),
            'response': response
        })
        
        return {
            'query': query,
            'response': response,
            'provider': provider or self.llm_manager.config.get('default_provider'),
            'data_context': data_context,
            'processing_time': time.time()
        }
    
    def _build_enhanced_prompt(self, query: str, data_context: Optional[Dict[str, Any]] = None) -> str:
        """Build enhanced prompt with context.
        
        Args:
            query: Original query
            data_context: Data context
            
        Returns:
            Enhanced prompt
        """
        prompt_parts = [
            "You are an expert data analyst helping with comprehensive data analysis.",
            "",
            "Context:"
        ]
        
        if data_context:
            if 'data_summary' in data_context:
                prompt_parts.append(f"Data Summary: {data_context['data_summary']}")
            
            if 'analysis_results' in data_context:
                prompt_parts.append(f"Previous Analysis: {data_context['analysis_results']}")
            
            if 'business_context' in data_context:
                prompt_parts.append(f"Business Context: {data_context['business_context']}")
        
        prompt_parts.extend([
            "",
            "User Query:",
            query,
            "",
            "Please provide a comprehensive, actionable response that includes:",
            "1. Analysis of the question/request",
            "2. Specific insights based on the data context",
            "3. Actionable recommendations",
            "4. Next steps or follow-up questions"
        ])
        
        return "\n".join(prompt_parts)
    
    def get_conversation_history(self) -> List[Dict[str, Any]]:
        """Get conversation history.
        
        Returns:
            List of conversation entries
        """
        return self.conversation_history.copy()
    
    def clear_conversation_history(self):
        """Clear conversation history."""
        self.conversation_history.clear()
        self.logger.info("Conversation history cleared")

class InteractiveAnalysisSession:
    """Interactive analysis session with LLM integration."""
    
    def __init__(self, config: Dict[str, Any]):
        """Initialize interactive session.
        
        Args:
            config: System configuration
        """
        self.config = config
        self.logger = get_logger(__name__)
        self.llm_manager = LLMManager(config.get('llm', {}))
        self.query_engine = NaturalLanguageQueryEngine(self.llm_manager)
        self.current_data = None
        self.current_data_summary = None
    
    async def start_session(self):
        """Start interactive analysis session."""
        self.logger.info("Starting interactive LLM analysis session")
        
        print("🤖 Welcome to CCGL Analytics System - AI Enhanced Mode")
        print("=" * 60)
        print("Available LLM providers:", ", ".join(self.llm_manager.list_available_providers()))
        print("Type 'help' for commands, 'exit' to quit")
        print("=" * 60)
        
        while True:
            try:
                user_input = input("\n🔍 Query> ").strip()
                
                if user_input.lower() in ['exit', 'quit', 'q']:
                    print("👋 Goodbye!")
                    break
                
                elif user_input.lower() == 'help':
                    self._show_help()
                
                elif user_input.lower() == 'providers':
                    self._show_providers()
                
                elif user_input.lower() == 'history':
                    self._show_history()
                
                elif user_input.lower() == 'clear':
                    self.query_engine.clear_conversation_history()
                    print("📝 Conversation history cleared")
                
                elif user_input.lower().startswith('load '):
                    await self._load_data(user_input[5:].strip())
                
                elif user_input.lower().startswith('provider '):
                    await self._set_provider(user_input[9:].strip())
                
                elif user_input.lower() == 'data':
                    self._show_data_summary()
                
                elif user_input.startswith('!'):
                    # System command
                    await self._execute_system_command(user_input[1:].strip())
                
                elif user_input:
                    # Natural language query
                    await self._process_natural_language_query(user_input)
                
            except KeyboardInterrupt:
                print("\n👋 Session interrupted. Goodbye!")
                break
            except EOFError:
                print("\n👋 Session ended. Goodbye!")
                break
            except Exception as e:
                self.logger.error(f"Session error: {e}")
                print(f"❌ Error: {e}")
    
    def _show_help(self):
        """Show help information."""
        help_text = """
🤖 CCGL Analytics - AI Enhanced Mode Commands:

Data Management:
  load <file>        - Load data from file (CSV, Excel, JSON)
  data               - Show current data summary

Analysis:
  <natural query>    - Ask any question about your data
  provider <name>    - Switch LLM provider (openai, claude, zhipuai, qwen)
  
Session Management:
  providers          - List available LLM providers
  history            - Show conversation history
  clear              - Clear conversation history
  help               - Show this help
  exit/quit/q        - Exit session

System Commands (prefix with !):
  !status            - Show system status
  !config            - Show configuration
  
Examples:
  "What patterns do you see in the sales data?"
  "How can I improve customer retention?"
  "Are there any anomalies in the recent transactions?"
  "Recommend next steps for analysis"
        """
        print(help_text)
    
    def _show_providers(self):
        """Show available providers."""
        providers = self.llm_manager.list_available_providers()
        current_provider = self.llm_manager.config.get('default_provider', 'None')
        
        print(f"\n🔧 Available LLM Providers:")
        for provider in providers:
            marker = "✅" if provider == current_provider else "  "
            print(f"  {marker} {provider}")
        
        print(f"\nCurrent default: {current_provider}")
    
    def _show_history(self):
        """Show conversation history."""
        history = self.query_engine.get_conversation_history()
        
        if not history:
            print("📝 No conversation history")
            return
        
        print(f"\n📝 Conversation History ({len(history)} entries):")
        print("-" * 50)
        
        for i, entry in enumerate(history[-5:], 1):  # Show last 5 entries
            timestamp = entry['timestamp']
            query = entry['query'][:80] + "..." if len(entry['query']) > 80 else entry['query']
            provider = entry['provider']
            
            print(f"{i}. [{timestamp}] ({provider})")
            print(f"   Q: {query}")
            print()
    
    async def _load_data(self, file_path: str):
        """Load data from file.
        
        Args:
            file_path: Path to data file
        """
        try:
            if not os.path.exists(file_path):
                print(f"❌ File not found: {file_path}")
                return
            
            # Load data based on file extension
            file_ext = Path(file_path).suffix.lower()
            
            if file_ext == '.csv':
                self.current_data = pd.read_csv(file_path)
            elif file_ext in ['.xlsx', '.xls']:
                self.current_data = pd.read_excel(file_path)
            elif file_ext == '.json':
                self.current_data = pd.read_json(file_path)
            else:
                print(f"❌ Unsupported file format: {file_ext}")
                return
            
            # Generate data summary
            self.current_data_summary = {
                'shape': self.current_data.shape,
                'columns': list(self.current_data.columns),
                'dtypes': self.current_data.dtypes.to_dict(),
                'missing_values': self.current_data.isnull().sum().to_dict(),
                'numeric_columns': list(self.current_data.select_dtypes(include=['number']).columns)
            }
            
            print(f"✅ Data loaded successfully from {file_path}")
            print(f"   Shape: {self.current_data.shape[0]} rows, {self.current_data.shape[1]} columns")
            
        except Exception as e:
            self.logger.error(f"Failed to load data: {e}")
            print(f"❌ Failed to load data: {e}")
    
    async def _set_provider(self, provider_name: str):
        """Set LLM provider.
        
        Args:
            provider_name: Name of the provider
        """
        available_providers = self.llm_manager.list_available_providers()
        
        if provider_name not in available_providers:
            print(f"❌ Provider '{provider_name}' not available")
            print(f"Available providers: {', '.join(available_providers)}")
            return
        
        self.llm_manager.config['default_provider'] = provider_name
        print(f"✅ Switched to provider: {provider_name}")
    
    def _show_data_summary(self):
        """Show current data summary."""
        if self.current_data is None:
            print("📊 No data loaded. Use 'load <file>' to load data.")
            return
        
        print(f"\n📊 Current Data Summary:")
        print(f"  Shape: {self.current_data_summary['shape']}")
        print(f"  Columns: {len(self.current_data_summary['columns'])}")
        print(f"  Numeric columns: {len(self.current_data_summary['numeric_columns'])}")
        
        missing_count = sum(v for v in self.current_data_summary['missing_values'].values() if v > 0)
        if missing_count > 0:
            print(f"  Missing values: {missing_count} total")
    
    async def _execute_system_command(self, command: str):
        """Execute system command.
        
        Args:
            command: System command
        """
        if command == 'status':
            print("🔧 System Status:")
            print(f"  LLM Providers: {len(self.llm_manager.list_available_providers())}")
            print(f"  Data Loaded: {'Yes' if self.current_data is not None else 'No'}")
            print(f"  Conversation Entries: {len(self.query_engine.get_conversation_history())}")
        
        elif command == 'config':
            print("⚙️ Configuration Summary:")
            print(f"  Default Provider: {self.llm_manager.config.get('default_provider')}")
            print(f"  Available Providers: {', '.join(self.llm_manager.list_available_providers())}")
        
        else:
            print(f"❌ Unknown system command: {command}")
    
    async def _process_natural_language_query(self, query: str):
        """Process natural language query.
        
        Args:
            query: Natural language query
        """
        print("🤔 Processing your question...")
        
        # Build data context
        data_context = {}
        if self.current_data_summary:
            data_context['data_summary'] = self.current_data_summary
        
        try:
            result = await self.query_engine.process_query(query, data_context)
            
            print(f"\n🤖 Response from {result['provider']}:")
            print("-" * 50)
            print(result['response'])
            
        except Exception as e:
            self.logger.error(f"Query processing failed: {e}")
            print(f"❌ Failed to process query: {e}")

def main():
    """Main entry point for LLM mode."""
    parser = argparse.ArgumentParser(
        description="CCGL Analytics System - LLM Integration Mode",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s --interactive
  %(prog)s --query "What patterns are in the sales data?" --data sales.csv
  %(prog)s --provider claude --interactive
        """
    )
    
    parser.add_argument(
        '-c', '--config',
        default='config.yml',
        help='Configuration file path (default: config.yml)'
    )
    
    parser.add_argument(
        '--interactive', '-i',
        action='store_true',
        help='Start interactive session'
    )
    
    parser.add_argument(
        '--query', '-q',
        help='Single natural language query'
    )
    
    parser.add_argument(
        '--data',
        help='Data file for context'
    )
    
    parser.add_argument(
        '--provider', '-p',
        help='LLM provider to use (openai, claude, zhipuai, qwen)'
    )
    
    parser.add_argument(
        '--output', '-o',
        help='Output file for results'
    )
    
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='Enable verbose logging'
    )
    
    args = parser.parse_args()
    
    # Load configuration
    try:
        with open(args.config, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
    except FileNotFoundError:
        print(f"Configuration file not found: {args.config}")
        sys.exit(1)
    except yaml.YAMLError as e:
        print(f"Error parsing configuration file: {e}")
        sys.exit(1)
    
    # Setup logging
    logging_config = config.get('logging', {})
    setup_logging(
        level='DEBUG' if args.verbose else logging_config.get('level', 'INFO'),
        format_type=logging_config.get('format', 'text'),
        log_file=logging_config.get('file'),
    )
    
    logger = get_logger(__name__)
    logger.info("Starting CCGL Analytics System - LLM Mode")
    
    async def main_async():
        if args.interactive:
            # Interactive mode
            session = InteractiveAnalysisSession(config)
            await session.start_session()
        
        elif args.query:
            # Single query mode
            llm_manager = LLMManager(config.get('llm', {}))
            query_engine = NaturalLanguageQueryEngine(llm_manager)
            
            # Load data if provided
            data_context = {}
            if args.data:
                try:
                    if args.data.endswith('.csv'):
                        data = pd.read_csv(args.data)
                    elif args.data.endswith(('.xlsx', '.xls')):
                        data = pd.read_excel(args.data)
                    elif args.data.endswith('.json'):
                        data = pd.read_json(args.data)
                    else:
                        print(f"Unsupported file format: {args.data}")
                        return 1
                    
                    data_context['data_summary'] = {
                        'shape': data.shape,
                        'columns': list(data.columns),
                        'dtypes': data.dtypes.to_dict()
                    }
                    
                except Exception as e:
                    print(f"Failed to load data: {e}")
                    return 1
            
            # Process query
            try:
                result = await query_engine.process_query(
                    args.query, 
                    data_context, 
                    args.provider
                )
                
                print(f"Query: {result['query']}")
                print(f"Provider: {result['provider']}")
                print("-" * 50)
                print(result['response'])
                
                # Save to file if specified
                if args.output:
                    with open(args.output, 'w', encoding='utf-8') as f:
                        json.dump(result, f, indent=2, ensure_ascii=False)
                    print(f"\nResults saved to: {args.output}")
                
            except Exception as e:
                logger.error(f"Query processing failed: {e}")
                print(f"Error: {e}")
                return 1
        
        else:
            print("Error: Either --interactive or --query must be specified")
            return 1
        
        return 0
    
    # Run main async function
    try:
        return asyncio.run(main_async())
    except KeyboardInterrupt:
        logger.info("LLM system interrupted by user")
        return 130

if __name__ == "__main__":
    sys.exit(main())